version: '3.8'

services:
  react-frontend:
    build:
      context: .././FE
    container_name: react-nginx
    ports:
      - "3000:80"
    environment:
      - REACT_APP_URL_BACKEND=${URL_SERVER_APP}
      - REACT_APP_URL_FRONTEND=${URL_CLIENT}
      - REACT_APP_URL_AI=${URL_AI}
      - REACT_APP_GOOGLE_MAPS_API_KEY=${REACT_APP_GOOGLE_MAPS_API_KEY}
      - REACT_APP_RAPID_API_TRAVEL_API_KEY=${REACT_APP_RAPID_API_TRAVEL_API_KEY}
      - REACT_APP_RAPID_API_WEATHER_API_KEY=${REACT_APP_RAPID_API_WEATHER_API_KEY}
      - REACT_APP_PAYOS_SCRIPT=${REACT_APP_PAYOS_SCRIPT}
    depends_on:
      - spring-backend
    networks:
      - app_network

  spring-backend:
    image: 'spring-app:latest'
    build:
      context: App_Service
    container_name: spring
    depends_on:
      - postgres-db
      - elasticsearch
      - kafka
      - mongodb
    develop:
      watch:
        - action: rebuild
          path: App_Service/src
        - action: rebuild
          path: App_Service/pom.xml
    volumes:
      - ./src:/app/src
      - ./target:/app/target
      - ./logs:/app/logs
    env_file:
      - .env.prod
    environment:
      - TZ=Asia/Ho_Chi_Minh
      - SPRING_PROFILES_ACTIVE=prod
      - DB_HOST=${DB_HOST}
      - URL_CLIENT=${URL_CLIENT}
      - AWS_S3_BUCKET=${AWS_S3_BUCKET}
      - URL_SERVER_APP=${URL_SERVER_APP}
      - CLIENT_ID=${CLIENT_ID}
      - API_KEY=${API_KEY}
      - DB_PORT=${DB_PORT}
      - CHECK_SUM_KEY=${CHECK_SUM_KEY}
      - GOOGLE_CLIENT_ID=${GOOGLE_CLIENT_ID}
      - GOOGLE_CLIENT_SECRET=${GOOGLE_CLIENT_SECRET}
      - DB_NAME=${DB_NAME}
      - DB_USER=${DB_USER}
      - DB_PASS=${DB_PASS}
      - SPRING_JPA_HIBERNATE_DDL_AUTO=update
      - ELASTICSEARCH_HOST=${ELASTICSEARCH_HOST}
      - ELASTICSEARCH_PORT=${ELASTICSEARCH_PORT}
      - KAFKA_TOPIC_PREDICT_REQUEST_EVENTS=${KAFKA_TOPIC_PREDICT_REQUEST_EVENTS}
      - KAFKA_TOPIC_TRAINING_REQUEST_EVENTS=${KAFKA_TOPIC_TRAINING_REQUEST_EVENTS}
      - KAFKA_BOOTSTRAP=${KAFKA_BOOTSTRAP}
      - SPRING_APPLICATION_JSON={"spring.data.mongodb.uri":"${MONGODB_URI}"}
    ports:
      - "8080:8080"
    networks:
      - app_network

  postgres-db:
    # image: 'postgres:17.2-alpine3.21'
    image: 'postgres:15'
    container_name: pgsql
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./Init_Database:/init_scripts 
    ports:
      - "5433:5432"
    environment:
      - POSTGRES_USER=${DB_USER}
      - POSTGRES_PASSWORD=${DB_PASS}
      - POSTGRES_DB=${DB_NAME}
    networks:
      - app_network

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.17.0
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    networks:
      - app_network
  zookeeper:
    image: wurstmeister/zookeeper
    container_name: zookeeper
    environment:
      - ZOOKEEPER_CLIENT_PORT=${ZOOKEEPER_CLIENT_PORT}
      - ZOOKEEPER_TICK_TIME=2000
    ports:
      - "2181:2181"
      - "2888:2888"
      - "3888:3888"
    networks:
      - app_network
    volumes:
      - zookeeper-data:/data
      - zookeeper-logs:/datalog
  kafka:
    image: wurstmeister/kafka
    platform: linux/amd64
    container_name: kafka
    ports:
      - "9092:9092"
    depends_on:
      - zookeeper
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_ZOOKEEPER_CONNECT=${KAFKA_ZOOKEEPER_CONNECT}
      - KAFKA_LISTENERS=${KAFKA_LISTENERS}
      - KAFKA_ADVERTISED_LISTENERS=${KAFKA_ADVERTISED_LISTENERS}
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_MESSAGE_MAX_BYTES=200000000
      - KAFKA_SOCKET_REQUEST_MAX_BYTES=210000000
    networks:
      - app_network
    volumes:
      - kafka-data:/var/lib/kafka/data

  debezium:
    image: debezium/connect:2.7.3.Final
    ports:
      - "8083:8083"
    depends_on:
      - kafka

    environment:
      BOOTSTRAP_SERVERS: kafka:9092
      GROUP_ID: 1
      CONFIG_STORAGE_TOPIC: debezium_config
      OFFSET_STORAGE_TOPIC: debezium_offsets
      STATUS_STORAGE_TOPIC: debezium_status
      PRODUCER_MAX_REQUEST_SIZE: 200000000
      CONSUMER_MAX_PARTITION_FETCH_BYTES: 200000000
      FETCH_MESSAGE_MAX_BYTES: 200000000

    networks:
      - app_network

  connector-register:
    image: curlimages/curl
    depends_on:
      - debezium
    entrypoint: >
      sh -c '
        echo "⏳ Waiting for Kafka Connect...";
        until curl -s http://debezium:8083/; do
          sleep 10;
        done;
        echo "✅ Registering connector...";
        curl -X POST http://debezium:8083/connectors \
          -H "Content-Type: application/json" \
          -d @/config/register-postgres-connector.json;
      '
    volumes:
      - ./register-postgres-connector.json:/config/register-postgres-connector.json
    networks:
      - app_network


  mongodb:
    image: mongo:latest
    container_name: mongodb
    ports:
      - "27017:27017"
    environment:
      - MONGO_INITDB_ROOT_USERNAME=${MONGO_INITDB_ROOT_USERNAME}
      - MONGO_INITDB_ROOT_PASSWORD=${MONGO_INITDB_ROOT_PASSWORD}
    volumes:
      - mongo-data:/data/db
    networks:
      - app_network
  ai-service:
    image: ai-service:latest
    build:
      context: ./AI_Service
    container_name: ai-service
    depends_on:
      - mongodb
    environment:
      - MONGODB_URI=${MONGODB_URI}
      - BROKER_URL=${BROKER_URL}
      - CANCEL_TOPIC=${CANCEL_TOPIC}
      - TRAINING_TOPIC=${TRAINING_TOPIC}
      - CANCEL_RESULT_TOPIC=${CANCEL_RESULT_TOPIC}
      - MODEL_PATH=${MODEL_PATH}
      - USER_BEHAVIOR_TOPIC=${USER_BEHAVIOR_TOPIC}

    ports:
      - "5000:5000"
    volumes:
      - ai-models-data:/app/app/models/cancel_prediction
    networks:
      - app_network

volumes:
  elasticsearch-data:
  postgres-data:
  kafka-data:
  zookeeper-data:
  zookeeper-logs:
  mongo-data:
  ai-models-data:
networks:
  app_network:
    driver: bridge
